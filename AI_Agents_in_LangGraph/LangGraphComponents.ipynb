{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateGraph, END \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypedDict, Annotated\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m \u001b[38;5;66;03m# Agent states\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END \n",
    "from typing import TypedDict, Annotated\n",
    "import operator # Agent states\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_groq import Groq # langchain wrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TavilySearchResults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[43mTavilySearchResults\u001b[49m(max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(tool))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tool\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TavilySearchResults' is not defined"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TypedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAgentState\u001b[39;00m(\u001b[43mTypedDict\u001b[49m):\n\u001b[0;32m      2\u001b[0m     messages: Annotated[\u001b[38;5;28mlist\u001b[39m[AnyMessage], operator\u001b[38;5;241m.\u001b[39madd]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TypedDict' is not defined"
     ]
    }
   ],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "# simple agent: annotated list of messages as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbind_tools(tools)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# conditional edge (any tool calls return True)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: \u001b[43mAgentState\u001b[49m):\n\u001b[0;32m     24\u001b[0m     result \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result\u001b[38;5;241m.\u001b[39mtool_calls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AgentState' is not defined"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    # call groq\n",
    "    # check weather an action present\n",
    "    # take that action\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_groq)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        # check weather an action present\n",
    "        graph.add_condiontionl_edges(\n",
    "            \"llm\", # node where the edge start\n",
    "            ..., # function \n",
    "            {True: \"action\", False: END} # how to map response of the function for next node\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\") # regular edge action to llm\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile() # create a langchain runnable\n",
    "        self.tools = {t.name: t for t in tools} \n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "# conditional edge (any tool calls return True)\n",
    "def exists_action(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "# llm node (function)\n",
    "def call_groq(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    if self.system:\n",
    "        messages = [SystemMessage(content=self.system)] + messages\n",
    "    message = self.model.invoke(messages)\n",
    "    return {'messages': [message]}\n",
    "\n",
    "def take_actions(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    for t in tool_calls:\n",
    "        print(f\"Calling: {t}\")\n",
    "        result = self.tools[t['name']].invoke(t['args'])\n",
    "        results.append(ToolMessage(tool_call_id=t['id'], name=t['name']))\n",
    "    print(\"Back to the model!\")\n",
    "    return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lang graph\n",
    "# Describe and Orchestrate the controlflow\n",
    "    # Cyclic Graphs - remember previous \n",
    "    # Presistence - remember previous iterations, have multiple conversations\n",
    "    # Human in the loop\n",
    "# Nodes: Agents or functions\n",
    "# Edges: connect nodes\n",
    "# Conditional edges: decisions\n",
    "\n",
    "# Agent State: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatGroq(model=\" \")  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying langgraph\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['messages'][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
